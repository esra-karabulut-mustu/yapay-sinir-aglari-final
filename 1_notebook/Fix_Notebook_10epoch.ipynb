{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC Pipeline - Grad-CAM Compatible Version (10 Epochs Demo)\n",
    "\n",
    "Bu notebook, Grad-CAM ile uyumlu model mimarisi kullanƒ±r.\n",
    "\n",
    "## Temel Fark\n",
    "\n",
    "**Orijinal:** `preprocess_input` model i√ßinde\n",
    "```python\n",
    "x = keras.applications.mobilenet_v2.preprocess_input(inputs)  # Model i√ßinde\n",
    "x = base_model(x)\n",
    "```\n",
    "\n",
    "**Fix'li:** `preprocess_input` veri pipeline'ƒ±nda\n",
    "```python\n",
    "# Model sadece base_model kullanƒ±r\n",
    "x = base_model(inputs)\n",
    "\n",
    "# Preprocessing veri y√ºklemede:\n",
    "dataset = dataset.map(lambda img, label: (\n",
    "    keras.applications.mobilenet_v2.preprocess_input(img), label\n",
    "))\n",
    "```\n",
    "\n",
    "## Demo Ayarlarƒ±\n",
    "\n",
    "- **EPOCHS:** 10 (hƒ±zlƒ± test i√ßin)\n",
    "- **Ama√ß:** Grad-CAM'in √ßalƒ±≈ütƒ±ƒüƒ±nƒ± doƒürulamak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: pip: command not found\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q kagglehub tensorflow matplotlib scikit-learn pandas tf-keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /home/burak/.cache/kagglehub/datasets/nodoubttome/skin-cancer9-classesisic/1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 786M/786M [00:28<00:00, 28.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: /home/burak/.cache/kagglehub/datasets/nodoubttome/skin-cancer9-classesisic/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download dataset\n",
    "import kagglehub\n",
    "dataset_path = kagglehub.dataset_download('nodoubttome/skin-cancer9-classesisic')\n",
    "print(f\"Dataset downloaded to: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 04:37:29.486360: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "IMG_SIZE = (224, 224)\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10  # Demo: hƒ±zlƒ± test\n",
    "SEED = 42\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/burak/.cache/kagglehub/datasets/nodoubttome/skin-cancer9-classesisic/versions/1/skin-cancer9-classesisic'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Find all images\u001b[39;00m\n\u001b[32m      8\u001b[39m image_data = []\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     10\u001b[39m     class_path = os.path.join(data_dir, class_name)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(class_path):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/burak/.cache/kagglehub/datasets/nodoubttome/skin-cancer9-classesisic/versions/1/skin-cancer9-classesisic'"
     ]
    }
   ],
   "source": [
    "# Load and analyze dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join(dataset_path, 'skin-cancer9-classesisic')\n",
    "\n",
    "# Find all images\n",
    "image_data = []\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for img_file in os.listdir(class_path):\n",
    "        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_data.append({\n",
    "                'path': os.path.join(class_path, img_file),\n",
    "                'class': class_name\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(image_data)\n",
    "class_counts = df['class'].value_counts()\n",
    "print(f\"\\nTotal images: {len(df)}\")\n",
    "print(f\"\\nClass distribution:\\n{class_counts}\")\n",
    "\n",
    "# Select top 2 classes\n",
    "top_classes = class_counts.head(2).index.tolist()\n",
    "df_filtered = df[df['class'].isin(top_classes)].copy()\n",
    "print(f\"\\nSelected classes: {top_classes}\")\n",
    "print(f\"Filtered dataset size: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Encode labels\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(top_classes)}\n",
    "df_filtered['label'] = df_filtered['class'].map(class_to_idx)\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_filtered, test_size=0.3, stratify=df_filtered['label'], random_state=SEED\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, stratify=temp_df['label'], random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)}\")\n",
    "print(f\"Val: {len(val_df)}\")\n",
    "print(f\"Test: {len(test_df)}\")\n",
    "\n",
    "# Extract arrays\n",
    "train_paths = train_df['path'].values\n",
    "train_labels = train_df['label'].values\n",
    "val_paths = val_df['path'].values\n",
    "val_labels = val_df['label'].values\n",
    "test_paths = test_df['path'].values\n",
    "test_labels = test_df['label'].values\n",
    "\n",
    "class_names = tuple(top_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading functions\n",
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return img, label\n",
    "\n",
    "# Augmentation\n",
    "def augment(img, label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    img = tf.image.random_brightness(img, 0.2)\n",
    "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "    return img, label\n",
    "\n",
    "# Create datasets WITHOUT preprocessing (will add per-model)\n",
    "def create_dataset(paths, labels, batch_size, augment_data=False, preprocessing_fn=None):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if augment_data:\n",
    "        ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Apply model-specific preprocessing if provided\n",
    "    if preprocessing_fn is not None:\n",
    "        def apply_preprocessing(img, label):\n",
    "            # Preprocessing expects [0, 255] range\n",
    "            img = img * 255.0\n",
    "            img = preprocessing_fn(img)\n",
    "            return img, label\n",
    "        ds = ds.map(apply_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload models_fixed.py\n",
    "!echo \"Upload 'models_fixed.py' file to /content/\"\n",
    "\n",
    "# Verify\n",
    "!ls -lh /content/models_fixed.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fixed models\n",
    "from models_fixed import (\n",
    "    create_scratch_cnn_fixed,\n",
    "    create_mobilenet_fixed,\n",
    "    create_efficientnet_fixed,\n",
    "    unfreeze_and_recompile\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Fixed models imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Scratch CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for Scratch CNN (no preprocessing)\n",
    "train_ds_scratch = create_dataset(train_paths, train_labels, BATCH_SIZE, augment_data=True)\n",
    "val_ds_scratch = create_dataset(val_paths, val_labels, BATCH_SIZE)\n",
    "\n",
    "# Create model\n",
    "scratch_model = create_scratch_cnn_fixed(IMG_SHAPE)\n",
    "scratch_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks_scratch = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"üöÄ Training Scratch CNN...\")\n",
    "history_scratch = scratch_model.fit(\n",
    "    train_ds_scratch,\n",
    "    validation_data=val_ds_scratch,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_scratch\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Scratch CNN training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MobileNetV2 (Fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets WITH MobileNet preprocessing\n",
    "mobilenet_preprocess = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "train_ds_mobilenet = create_dataset(\n",
    "    train_paths, train_labels, BATCH_SIZE, \n",
    "    augment_data=True, preprocessing_fn=mobilenet_preprocess\n",
    ")\n",
    "val_ds_mobilenet = create_dataset(\n",
    "    val_paths, val_labels, BATCH_SIZE,\n",
    "    preprocessing_fn=mobilenet_preprocess\n",
    ")\n",
    "\n",
    "# Create model (preprocessing external!)\n",
    "mobilenet_model = create_mobilenet_fixed(IMG_SHAPE, trainable=False)\n",
    "\n",
    "callbacks_mobilenet = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"üöÄ Training MobileNetV2 (Fixed)...\")\n",
    "history_mobilenet = mobilenet_model.fit(\n",
    "    train_ds_mobilenet,\n",
    "    validation_data=val_ds_mobilenet,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_mobilenet\n",
    ")\n",
    "\n",
    "print(\"‚úÖ MobileNetV2 training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train EfficientNetB0 (Fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets WITH EfficientNet preprocessing\n",
    "efficientnet_preprocess = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "train_ds_efficient = create_dataset(\n",
    "    train_paths, train_labels, BATCH_SIZE,\n",
    "    augment_data=True, preprocessing_fn=efficientnet_preprocess\n",
    ")\n",
    "val_ds_efficient = create_dataset(\n",
    "    val_paths, val_labels, BATCH_SIZE,\n",
    "    preprocessing_fn=efficientnet_preprocess\n",
    ")\n",
    "\n",
    "# Create model (preprocessing external!)\n",
    "efficientnet_model = create_efficientnet_fixed(IMG_SHAPE, trainable=False)\n",
    "\n",
    "callbacks_efficient = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"üöÄ Training EfficientNetB0 (Fixed)...\")\n",
    "history_efficient = efficientnet_model.fit(\n",
    "    train_ds_efficient,\n",
    "    validation_data=val_ds_efficient,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_efficient\n",
    ")\n",
    "\n",
    "print(\"‚úÖ EfficientNetB0 training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Grad-CAM (should work now!)\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_gradcam(model, model_name, img_path, preprocessing_fn=None):\n",
    "    \"\"\"Test if Grad-CAM works on the fixed model.\"\"\"\n",
    "    print(f\"\\nTesting Grad-CAM on {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img_resized = tf.image.resize(img, IMG_SIZE)\n",
    "        original = img_resized.numpy() / 255.0\n",
    "        \n",
    "        # Preprocess\n",
    "        if preprocessing_fn:\n",
    "            prep = preprocessing_fn(img_resized.numpy())\n",
    "        else:\n",
    "            prep = img_resized.numpy() / 255.0\n",
    "        prep = np.expand_dims(prep, 0)\n",
    "        \n",
    "        # Create Gradcam\n",
    "        gradcam = Gradcam(model, model_modifier=ReplaceToLinear(), clone=False)\n",
    "        \n",
    "        def score_fn(output):\n",
    "            return output[:, 0]\n",
    "        \n",
    "        # Generate\n",
    "        cam = gradcam(score_fn, prep, penultimate_layer=-1)\n",
    "        heatmap = cam[0]\n",
    "        \n",
    "        # Resize\n",
    "        heatmap_resized = tf.image.resize(\n",
    "            heatmap[..., np.newaxis], IMG_SIZE\n",
    "        ).numpy().squeeze()\n",
    "        \n",
    "        if heatmap_resized.max() > 0:\n",
    "            heatmap_resized /= heatmap_resized.max()\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        axes[0].imshow(original)\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(heatmap_resized, cmap='jet')\n",
    "        axes[1].set_title('Grad-CAM')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        overlay = 0.6 * original + 0.4 * plt.cm.jet(heatmap_resized)[:, :, :3]\n",
    "        axes[2].imshow(np.clip(overlay, 0, 1))\n",
    "        axes[2].set_title('Overlay')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'{model_name} - Grad-CAM Test ‚úÖ')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"  ‚úÖ SUCCESS! Grad-CAM works for {model_name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Test on one image from each model\n",
    "test_image = test_paths[0]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üî¨ GRAD-CAM COMPATIBILITY TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = {\n",
    "    'Scratch CNN': test_gradcam(scratch_model, 'Scratch CNN', test_image),\n",
    "    'MobileNetV2': test_gradcam(mobilenet_model, 'MobileNetV2', test_image, mobilenet_preprocess),\n",
    "    'EfficientNetB0': test_gradcam(efficientnet_model, 'EfficientNetB0', test_image, efficientnet_preprocess)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESULTS\")\n",
    "print(\"=\"*70)\n",
    "for model_name, success in results.items():\n",
    "    icon = \"‚úÖ\" if success else \"‚ùå\"\n",
    "    print(f\"  {icon} {model_name}\")\n",
    "\n",
    "if all(results.values()):\n",
    "    print(\"\\nüéâ ALL MODELS GRAD-CAM COMPATIBLE!\")\n",
    "    print(\"\\n‚úÖ Fix ba≈üarƒ±lƒ±! Artƒ±k t√ºm modellere Grad-CAM uygulayabilirsiniz.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some models failed. Check errors above.\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Bu notebook:\n",
    "1. ‚úÖ Modelleri fix'li mimari ile eƒüitti (10 epoch)\n",
    "2. ‚úÖ Grad-CAM uyumluluƒüunu test etti\n",
    "\n",
    "**Eƒüer test ba≈üarƒ±lƒ±ysa:**\n",
    "- Bu modelleri 100 epoch ile yeniden eƒüitin\n",
    "- Grad-CAM g√∂rsellerini olu≈üturun\n",
    "- outputs.zip'e ekleyin\n",
    "\n",
    "**Eƒüer test ba≈üarƒ±sƒ±zsa:**\n",
    "- Manuel Grad-CAM script'i deneyin\n",
    "- Ya da README ile pragmatik √ß√∂z√ºm√º kullanƒ±n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
